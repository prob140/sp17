<div id="ipython-notebook">
            <a class="interact-button" href="http://prob140.berkeley.edu/user-redirect/interact?repo=prob140&path=textbook/Chapter 21/21_0_Distributions_of_Sums.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Distributions-of-Sums">Distributions of Sums<a class="anchor-link" href="#Distributions-of-Sums">Â¶</a></h1><p>This chapter provides some general methods for working with sums of random variables, whether discrete or continuous.</p>
<p>We will start with the continuous analog of the convolution formula for the distribution of a sum of two independent discrete random variables.</p>
<p>We will then develop a more powerful version of the probability generating function that we defined earlier to study sums of independent random variables with finitely many non-negative integer values. The new version, called the <em>moment generating function,</em> will apply to all random variables, discrete and continuous, with finite or infinite sets of values.</p>
<p>In the process, we will be develop sharper tail bounds than the ones based on the inequalities of Markov and Chebychev.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div></div></div></div>