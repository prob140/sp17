<div id="ipython-notebook">
            <a class="interact-button" href="http://prob140.berkeley.edu/user-redirect/interact?repo=prob140&path=textbook/Chapter 22/22_1_Conditioning_on_a_Continuous_Variable.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conditioning-on-a-Continuous-Variable">Conditioning on a Continuous Variable<a class="anchor-link" href="#Conditioning-on-a-Continuous-Variable">¶</a></h3><p>Suppose $X$ is a random variable and $A$ is an event that depends on $X$.</p>
<p>If $X$ is a discrete random variable, then for any possible value $x$ of $X$ the quantity $P(A \mid X = x)$ has a clear definition by the division rule:</p>
$$
P(A \mid X = x) ~ = ~ \frac{P(A, X = x)}{P(X = x)}
$$<p>When $X$ is continuous, the denominator is 0. In this case there is one main idea to keep in mind:</p>
<ul>
<li>$P(A \mid X \in dx)$ is essentially constant over the entire infinitesimal interval $dx$. This constant value will be denoted $P(A \mid X = x)$.</li>
</ul>
<p>So for continuous $X$, we will define
$$
P(A \mid X = x) ~ = ~ P(A \mid X \in dx) ~ \sim ~ \frac{P(A, X \in dx)}{P(X \in dx)} 
$$</p>
<p>We are assuming that the limit of the right hand side as $dx$ goes to 0 exists and doesn't depend exactly how $dx$ is defined: around $x$, or to the left of $x$, or to the right, and so on. This will be true under regularity conditions; you can just assume it works.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Average-Conditional-Probabilities">Average Conditional Probabilities<a class="anchor-link" href="#Average-Conditional-Probabilities">¶</a></h3><p>We can now use our new notation and the multiplication rule to get</p>
$$
P(A, X \in dx) ~ = ~ P(X \in dx)P(A \mid X = x) ~ \sim ~ f_X(x)dxP(A \mid X = x)
$$<p>Thus if $A$ is an event and $X$ a continuous random variable with density $f_X$, then</p>
$$
P(A) ~ = ~ \int_{\text{all x}} P(A, X \in dx) ~ = ~ \int_{\text{all x}} P(A \mid X = x)f_X(x)dx
$$<p>In more compact notation, $P(A) = E(P(A \mid X))$ and thus is an example of finding expectation by conditioning.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-Toss-of-a-Random-Coin">One Toss of a Random Coin<a class="anchor-link" href="#One-Toss-of-a-Random-Coin">¶</a></h3><p>Let $X$ have any density on the unit interval $(0, 1)$. Think of the value of $X$ as the "$p$" of a coin, that is, the probability that the coin lands heads. Toss the coin once. Then 
$$
P(\text{coin lands heads} \mid X \in dp) ~ \sim ~ p
$$</p>
<p>regardless of exactly where $X$ is in the tiny interval around $p$. That is why this probability is called $P(\text{coin lands heads} \mid X = p)$.</p>
<p>Notice that the probability doesn't involve the density of $X$. Once you are given the value of $X$, there is no randomness left in $X$; it becomes a constant.</p>
<p>Let $X$ have density $f_X$. Then</p>
$$
P(\text{coin lands heads}, X \in dp) ~ = ~ P(X \in dp)P(\text{coin lands heads} \mid X = p) ~ \sim ~ f_X(p)dp \cdot p
$$<p>and so
$$
P(\text{coin lands heads}) ~ = ~ \int_0^1 p \cdot f_X(p)dp ~ = ~ E(X)
$$</p>
<p>Thus if $X$ is uniform on $(0, 1)$, that is, if $X$ has the beta $(1, 1)$ distribution, then the chance that the coin lands heads is $1/2$. If $X$ has the beta $(r, s)$ distribution then the chance that the coin lands heads is $r/(r+s)$.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Two-Tosses-of-a-Random-Coin">Two Tosses of a Random Coin<a class="anchor-link" href="#Two-Tosses-of-a-Random-Coin">¶</a></h3><p>Let $X$ be uniform on $(0, 1)$. Given $X = p$, toss a $p$-coin twice. We have just observed that $P(\text{first toss is a head}) = 1/2$. The first toss behaves like the toss of a fair coin.</p>
<p>Now let's figure out the chance that both the trials are successes. We know that $P(\text{both tosses are heads} \mid X = p) ~ \sim ~ p^2$. So</p>
$$
P(\text{both tosses are heads}) ~ = ~ \int_0^1 p^2 \cdot 1dp ~ = ~ \frac{1}{3}
$$<p>That's <em>greater than</em> $1/4$ which is the chance of two heads given that you are tossing a fair coin.</p>
<p>Let's see what's going on here. We know that</p>
\begin{align*}
P(\text{both tosses are heads}) ~ &amp;= ~ P(\text{first toss is a head})
P(\text{second toss is a head} \mid \text{first toss is a head}) \\
&amp;= ~ \frac{1}{2} P(\text{second toss is a head} \mid \text{first toss is a head})
\end{align*}<p>Therefore
$$
P(\text{second toss is a head} \mid \text{first toss is a head}) ~ = ~ \frac{2}{3} ~ &gt; ~ \frac{1}{2}
$$</p>
<p>Clearly, knowing that the first toss is a head is telling us something about $X$, which is then reflected is the chance that the second toss is also a head.</p>
<p>To quantify this idea, we will find the conditional density of $X$ given that the first toss is a head. A good way is to find $P(X \in dp \mid \text{first toss is a head})$. That's a "backwards in time" conditional probability and can be found using Bayes' Rule.</p>
\begin{align*}
P(X \in dp \mid \text{first toss is a head}) ~ &amp;= ~ \frac{P(X \in dp \text{ and first toss is a head})}{P(\text{first toss is a head})} \\
&amp;= ~ \frac{1dp \cdot p}{\frac{1}{2}} \\
&amp;= ~ 2p \cdot dp
\end{align*}<p>Thus the conditional density of $X$ given that the first toss is a head is not uniform. It is $f(p) = 2p$ for $p \in (0, 1)$, which rises linearly. It puts more of its mass on values near 1 than near 0. This makes sense: given that the first toss is a head, we are more inclined to believe that the coin is biased towards heads than towards tails.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkblue'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">2.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'$p$'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Conditional Density of $X$ given that the first trial is a success'</span><span class="p">);</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="../notebooks-images/22_1_Conditioning_on_a_Continuous_Variable_5_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now find $P(\text{second trial is a success} \mid \text{first trial is a success})$ using this conditional density.</p>
\begin{align*}
P(\text{second trial is a success} \mid \text{first trial is a success}) ~ &amp;= ~ E(X \mid \text{first trial is a success}) \\
&amp;= ~ \int_0^1 p \cdot 2p \cdot dp \\
&amp;= ~ \frac{2}{3}
\end{align*}</div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div></div></div></div>