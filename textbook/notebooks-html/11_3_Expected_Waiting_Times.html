<div id="ipython-notebook">
            <a class="interact-button" href="http://prob140.berkeley.edu/user-redirect/interact?repo=prob140&path=textbook/Chapter 11/11_3_Expected_Waiting_Times.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Expected-Waiting-Times">Expected Waiting Times<a class="anchor-link" href="#Expected-Waiting-Times">¶</a></h3><p>Let's find some expectations by conditioning. All of the calculations below involve conditioning on early moves of a random process.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Waiting-till-H">Waiting till H<a class="anchor-link" href="#Waiting-till-H">¶</a></h3><p>A coin lands heads with chance $p$. Let's call it a $p$-coin for short. Let $X$ be the number of tosses of a $p$-coin till the first head appears.</p>
<p>As you have seen in exercises, $X$ has the geometric $(p)$ distribution on $1, 2, 3, \ldots $. By using the tail sum formula for expectation, you have showed that $E(X) = \frac{1}{p}$. Here is a quicker way to arrive at the same result.</p>
<p>The method is based on representing $X$ as a mixture of two other random variables:</p>
<ul>
<li>With probability $p$, $X=1$.</li>
<li>With the remaining probability $q = 1-p$, the first toss is a tail, and then <em>the process starts over</em> independently of what has happened before. That is, with probability $q$, $X = 1 + X^*$ where $X^*$ is an independent copy of $X$.</li>
</ul>
<p>Therefore, by averaging conditional expectations,</p>
$$
E(X) = pE(1) ~ + ~ qE(1+X^*) = p + q(1+E(X^*)) = p + q(1+E(X))
$$<p>Solve for $E(X)$:
$$
E(X) = \frac{1}{p}
$$</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Waiting-Till-Both-Faces-Have-Appeared">Waiting Till Both Faces Have Appeared<a class="anchor-link" href="#Waiting-Till-Both-Faces-Have-Appeared">¶</a></h3><p>Suppose you toss the $p$-coin until both faces have appeared. Let $N$ be the number of tosses.</p>
<p><strong>Question.</strong> What is $E(N)$?</p>
<p><strong>Answer.</strong> By conditioning on the first toss:</p>
<ul>
<li>With probability $p$ the first toss is a head, so $N = 1 + W_T$ where $W_T$ has the geometric $(q)$ distribution.</li>
<li>With probability $q$ the first toss is a tail, so $N = 1 + W_H$ where $W_H$ has the geometric $(p)$ distribution.</li>
</ul>
<p>So</p>
$$
E(N) = p\big{(}1 + \frac{1}{q} \big{)} + q\big{(}1 + \frac{1}{p} \big{)}
= 1 + \frac{p^2 + q^2}{pq} = \frac{1 - pq}{pq}
$$</div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Waiting-till-HH">Waiting till HH<a class="anchor-link" href="#Waiting-till-HH">¶</a></h3><p>In tosses of a $p$-coin, let $W_{HH}$ be the number of tosses till you see two heads in a row.</p>
<p><strong> Question.</strong> What is $E(W_{HH})$?</p>
<p><strong>Answer 1.</strong> We can find this is several ways. One way is by conditioning on the first two tosses.</p>
<ul>
<li>With probability $q$, the first toss is a tail, so $W_{HH} = 1 + W^*$ where $W^*$ is an independent copy of $W_{HH}$.</li>
<li>With probability $pq$ the first two tosses are HT, and $W_{HH} = 2 + W^{**}$
where $W^{**}$ is an independent copy of $W_{HH}$.</li>
<li>With probability $p^2$, the first two tosses are heads, and $W_{HH} = 2$.</li>
</ul>
<p>So if $x = E(W_{HH})$ then
$$
x = q(1+x) + pq(2+x) + p^22
$$</p>
<p>So 
$$
x = \frac{q + 2pq + 2p^2}{1 - q - pq} 
= \frac{1+p}{p^2}
$$
by repeatedly using $p + q = 1$.</p>
<p><strong>Answer 2.</strong> Another way is by conditioning on $X$, the number of tosses till the first head. This is the same random variable $X$ as in the previous example. Notice that $W_{HH} = X + Y$ where:</p>
<ul>
<li>With probability $p$, the toss after $X$ is a head, so $Y = 1$.</li>
<li>With probability $q$, the toss after $X$ is a tail, so $Y = 1 + W^*$ where $W^*$ is an independent copy of $W_{HH}$.</li>
</ul>
<p>So if $x = E(W_{HH})$ then
$$
x = E(X) + E(Y) = \frac{1}{p} + p + q(1 + x)
$$
So
$$
px = \frac{1}{p} + 1 ~~~~ \text{and hence} ~~~~ x = \frac{1+p}{p^2}
$$
as before.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Gambler's-Ruin:-Duration-of-the-Game">Gambler's Ruin: Duration of the Game<a class="anchor-link" href="#Gambler's-Ruin:-Duration-of-the-Game">¶</a></h3><p>Let's return to the setting of the gambler's ruin problem with a fair coin. The gambler starts with $\$a$ and bets on a fair coin till he reaches either $\$b$ or $\$0$. Let $T$ be the duration of the game.</p>
<p><strong>Question.</strong> What is $E_a(T)$, the expected duration of the game given that the gambler starts with $\$a$?</p>
<p><strong>Answer.</strong> Let $E_k(T)$ denote the expected duration of the game given that the gambler starts with $\$k$. Then for $1 \le k \le b-1$,</p>
$$
E_k(T) = 1 + \frac{1}{2}E_{k-1}T + \frac{1}{2} E_{k+1}T
$$<p>where the edge cases are
$$
E_0(T) = 0 = E_b(T)
$$</p>
<p>You can check that the function $f(k) = k(b-k)$ satisfies this recursion, and hence that $E_a(T) = a(b-a)$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div></div></div></div>